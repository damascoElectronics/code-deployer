
stop:all_containers:
  stage: stop
  script:
    - echo '========================================='
    - echo 'EXPORTING DATA BEFORE STOPPING CONTAINERS'
    - echo '========================================='
    
    # Force immediate log download
    - echo ''
    - echo '=== Forcing immediate log download from VM2 to VM1 ==='
    - |
      if sudo docker ps | grep -q log_processor_container || docker ps | grep -q log_processor_container; then
        echo "Triggering immediate download by sending signal to container..."
        sleep 5
        echo "Waiting 15 seconds for downloads to complete..."
        sleep 15
      fi
    
    # Create artifacts directory structure
    - mkdir -p artifacts/vm1_downloaded_logs
    - mkdir -p artifacts/vm2_generated_logs
    - mkdir -p artifacts/container_logs
    - mkdir -p artifacts/grafana
    - mkdir -p artifacts/database
    
    # Export logs from VM1
    - echo ''
    - echo '=== Exporting logs from VM1 (log_processor) ==='
    - |
      if sudo docker ps -a | grep -q log_processor_container; then
        echo "Copying downloaded logs from log_processor container..."
        sudo docker cp log_processor_container:/app/downloaded_logs/. artifacts/vm1_downloaded_logs/ 2>/dev/null || \
        docker cp log_processor_container:/app/downloaded_logs/. artifacts/vm1_downloaded_logs/ 2>/dev/null || \
        echo "No downloaded logs found in VM1"
        
        echo "Copying processed files tracking log..."
        sudo docker cp log_processor_container:/app/downloaded_logs/.processed_files.txt artifacts/vm1_downloaded_logs/ 2>/dev/null || \
        docker cp log_processor_container:/app/downloaded_logs/.processed_files.txt artifacts/vm1_downloaded_logs/ 2>/dev/null || \
        echo "No processed files log found"
        
        echo "Saving VM1 container logs..."
        sudo docker logs log_processor_container > artifacts/container_logs/vm1_log_processor.log 2>&1 || \
        docker logs log_processor_container > artifacts/container_logs/vm1_log_processor.log 2>&1 || \
        echo "Could not export VM1 container logs"
      else
        echo "log_processor_container not found on VM1"
      fi
    
    # Export logs from VM2
    - echo ''
    - echo '=== Exporting logs from VM2 (log_collector) ==='
    - |
      if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 starion@192.168.0.11 'docker ps -a | grep -q log_collector_container'; then
        echo "Copying generated logs from log_collector container on VM2..."
        
        ssh -o StrictHostKeyChecking=no starion@192.168.0.11 "
          mkdir -p /tmp/vm2_export_logs && \
          docker cp log_collector_container:/app/logs/. /tmp/vm2_export_logs/ 2>/dev/null || \
          echo 'No logs in container'
        " || echo "Failed to copy from VM2 container"
        
        scp -r -o StrictHostKeyChecking=no -o ConnectTimeout=10 \
          starion@192.168.0.11:/tmp/vm2_export_logs/* \
          artifacts/vm2_generated_logs/ 2>/dev/null || echo "No generated logs found in VM2"
        
        echo "Saving VM2 container logs..."
        ssh -o StrictHostKeyChecking=no starion@192.168.0.11 \
          "docker logs log_collector_container" > artifacts/container_logs/vm2_log_collector.log 2>&1 || \
          echo "Could not export VM2 container logs"
        
        ssh -o StrictHostKeyChecking=no starion@192.168.0.11 "rm -rf /tmp/vm2_export_logs" || true
      else
        echo "log_collector_container not found on VM2"
      fi
    
    # Export Grafana data
    - echo ''
    - echo '=== Exporting Grafana data ==='
    - |
      if sudo docker ps -a | grep -q grafana; then
        echo "Exporting Grafana dashboards..."
        
        # Export dashboards via API
        curl -s -u ${GRAFANA_ADMIN_USER}:${GRAFANA_ADMIN_PASSWORD} \
          http://0.0.0.0:${GRAFANA_PORT}/api/dashboards/uid/keypool-logs-001 \
          > artifacts/grafana/dashboard_export.json 2>/dev/null || \
          echo "Could not export dashboard"
        
        # Export datasources
        curl -s -u ${GRAFANA_ADMIN_USER}:${GRAFANA_ADMIN_PASSWORD} \
          http://0.0.0.0:${GRAFANA_PORT}/api/datasources \
          > artifacts/grafana/datasources.json 2>/dev/null || \
          echo "Could not export datasources"
        
        # Save Grafana container logs
        echo "Saving Grafana container logs..."
        sudo docker logs grafana > artifacts/container_logs/grafana.log 2>&1 || \
        docker logs grafana > artifacts/container_logs/grafana.log 2>&1 || \
        echo "Could not export Grafana logs"
        
        # Take screenshot of metrics if possible (requires additional tools)
        echo "Grafana metrics saved to artifacts/grafana/"
      else
        echo "Grafana container not found"
      fi
    
    # Export Database
    - echo ''
    - echo '=== Exporting Database ==='
    - |
      if sudo docker ps -a | grep -q keypool_mysql || docker ps -a | grep -q keypool_mysql; then
        docker exec keypool_mysql mysqldump \
          -u ${MYSQL_USER} \
          -p${MYSQL_PASSWORD} \
          ${MYSQL_DATABASE} \
          > artifacts/database/keypool_logs_backup_$(date +%Y%m%d_%H%M%S).sql 2>/dev/null || \
          echo "Could not export database"
        
        # Export table statistics
        docker exec keypool_mysql mysql \
          -u ${MYSQL_USER} \
          -p${MYSQL_PASSWORD} \
          ${MYSQL_DATABASE} \
          -e "SELECT 'logs_data' as Table_Name, COUNT(*) as Records FROM logs_data;" \
          > artifacts/database/table_stats.txt 2>/dev/null || echo "No stats"
      else
        echo "MySQL container not found"
      fi
    
    # Create summary report
    - echo ''
    - echo '=== Creating summary report ==='
    - |
      cat > artifacts/SUMMARY_REPORT.txt << EOF
      =========================================================
                    SYSTEM SHUTDOWN SUMMARY
      =========================================================
      Export Date:     $(date '+%Y-%m-%d %H:%M:%S %Z')
      Pipeline ID:     $CI_PIPELINE_ID
      Job ID:          $CI_JOB_ID
      Commit SHA:      $CI_COMMIT_SHA
      Branch:          $CI_COMMIT_REF_NAME
      Triggered by:    $GITLAB_USER_LOGIN
      =========================================================
      
      COMPONENTS STATUS:
      ---------------------------------------------------------
      VM1 Components:
        - Log Processor: $(sudo docker ps | grep -q log_processor_container && echo "Running" || echo "Stopped")
        - MySQL:         $(sudo docker ps | grep -q keypool_mysql && echo "Running" || echo "Stopped")
        - Grafana:       $(sudo docker ps | grep -q grafana && echo "Running" || echo "Stopped")
      
      VM2 Components:
        - Log Collector: $(ssh -o StrictHostKeyChecking=no starion@192.168.0.11 'docker ps | grep -q log_collector_container' 2>/dev/null && echo "Running" || echo "Stopped/Unreachable")
      
      =========================================================
      
      DATA EXPORTED:
      ---------------------------------------------------------
      VM1 Downloaded Logs:
      $(ls -lh artifacts/vm1_downloaded_logs/ 2>/dev/null | tail -n +2 | head -5 || echo "No files found")
      Total: $(find artifacts/vm1_downloaded_logs/ -type f -name "*.log" 2>/dev/null | wc -l) files
      
      VM2 Generated Logs:
      $(ls -lh artifacts/vm2_generated_logs/ 2>/dev/null | tail -n +2 | head -5 || echo "No files found")
      Total: $(find artifacts/vm2_generated_logs/ -type f -name "*.log" 2>/dev/null | wc -l) files
      
      Database Backup:
      $(ls -lh artifacts/database/*.sql 2>/dev/null | tail -n +2 || echo "No backup found")
      
      Grafana Exports:
      $(ls -lh artifacts/grafana/ 2>/dev/null | tail -n +2 || echo "No exports found")
      
      Container Logs:
      $(ls -lh artifacts/container_logs/ 2>/dev/null | tail -n +2 || echo "No logs found")
      
      =========================================================
      
      STATISTICS:
      ---------------------------------------------------------
      Total artifacts size: $(du -sh artifacts/ 2>/dev/null | cut -f1 || echo "0")
      Database records:     $(cat artifacts/database/table_stats.txt 2>/dev/null | grep logs_data | awk '{print $4}' || echo "N/A")
      
      =========================================================
      EOF
    
    - echo ''
    - cat artifacts/SUMMARY_REPORT.txt
    - echo ''
    - echo 'All data exported successfully to artifacts/'
    
    # NOW STOP ALL CONTAINERS
    - echo ''
    - echo '========================================='
    - echo 'STOPPING ALL CONTAINERS'
    - echo '========================================='
    
    # Stop VM1 containers
    - echo ''
    - echo '=== Stopping VM1 containers ==='
    - echo 'Stopping log_processor...'
    - sudo docker stop log_processor_container || docker stop log_processor_container || echo 'log_processor was not running'
    - sudo docker rm log_processor_container || docker rm log_processor_container || echo 'log_processor was already removed'
    
    - echo 'Stopping MySQL...'
    - sudo docker stop keypool_mysql || docker stop keypool_mysql || echo 'MySQL was not running'
    - sudo docker rm keypool_mysql || docker rm keypool_mysql || echo 'MySQL was already removed'
    
    - echo 'Stopping Grafana...'
    - sudo docker stop grafana || docker stop grafana || echo 'Grafana was not running'
    - sudo docker rm grafana || docker rm grafana || echo 'Grafana was already removed'
    
    # Stop VM2 container
    - echo ''
    - echo '=== Stopping VM2 container ==='
    - ssh -o ConnectTimeout=30 -o StrictHostKeyChecking=no starion@192.168.0.11 '
        docker stop log_collector_container || echo "log_collector was not running";
        docker rm log_collector_container || echo "log_collector was already removed";
        docker stop ogs_data_generator_container || echo "ogs_data_generator was not running";
        docker rm ogs_data_generator_container || echo "ogs_data_generator was already removed";
      ' || echo 'Could not connect to VM2'
    
    # Final verification
    - echo ''
    - echo '=== Final verification ==='
    - echo 'VM1 containers status:'
    - sudo docker ps | grep -E "(log_processor|keypool_mysql|grafana)" || docker ps | grep -E "(log_processor|keypool_mysql|grafana)" || echo 'All VM1 containers stopped'
    - echo ''
    - echo 'VM2 container status:'
    - ssh -o ConnectTimeout=30 -o StrictHostKeyChecking=no starion@192.168.0.11 'docker ps | grep log_collector_container || echo "VM2 container stopped"' || echo 'Could not verify VM2'
    - ssh -o ConnectTimeout=30 -o StrictHostKeyChecking=no starion@192.168.0.11 'docker ps | grep ogs_data_generator_container || echo "VM2 container stopped"' || echo 'Could not verify VM2'
    
    - echo ''
    - echo '========================================='
    - echo 'ALL CONTAINERS STOPPED SUCCESSFULLY'
    - echo 'All data saved to artifacts/'
    - echo '========================================='
  
  artifacts:
    name: "system-shutdown-$CI_COMMIT_SHORT_SHA-$CI_PIPELINE_ID"
    paths:
      - artifacts/
    expire_in: 30 days
    when: always
  
  when: manual
  allow_failure: true
  only:
    - main
    - develop
    - merge_requests

# Export database separately (can be run without stopping containers)
stop:export_database:
  stage: stop
  script:
    - echo 'Exporting database without stopping services...'
    - mkdir -p artifacts/database
    - mkdir -p artifacts/database/csv
    
    # Full database dump
    - echo 'Creating full database dump...'
    - |
      docker exec keypool_mysql mysqldump \
        -u ${MYSQL_USER} \
        -p${MYSQL_PASSWORD} \
        ${MYSQL_DATABASE} \
        > artifacts/database/keypool_logs_full_$(date +%Y%m%d_%H%M%S).sql
    
    # Schema only dump
    - echo 'Creating schema-only dump...'
    - |
      docker exec keypool_mysql mysqldump \
        -u ${MYSQL_USER} \
        -p${MYSQL_PASSWORD} \
        --no-data \
        ${MYSQL_DATABASE} \
        > artifacts/database/keypool_logs_schema.sql
    
    # Data only dump
    - echo 'Creating data-only dump...'
    - |
      docker exec keypool_mysql mysqldump \
        -u ${MYSQL_USER} \
        -p${MYSQL_PASSWORD} \
        --no-create-info \
        ${MYSQL_DATABASE} \
        > artifacts/database/keypool_logs_data.sql
    
    # Export to CSV
    - echo 'Exporting to CSV format...'
    - |
      docker exec keypool_mysql mysql \
        -u ${MYSQL_USER} \
        -p${MYSQL_PASSWORD} \
        ${MYSQL_DATABASE} \
        -e "SELECT * FROM logs_data" \
        | tr '\t' ',' > artifacts/database/csv/logs_data.csv 2>/dev/null || echo "No data to export"
    
    # Database statistics
    - |
      cat > artifacts/database/DB_INFO.txt << EOF
      =========================================================
                    DATABASE EXPORT INFO
      =========================================================
      Export Date:     $(date '+%Y-%m-%d %H:%M:%S %Z')
      Pipeline ID:     $CI_PIPELINE_ID
      Commit SHA:      $CI_COMMIT_SHORT_SHA
      Branch:          $CI_COMMIT_REF_NAME
      
      DATABASE CONNECTION:
      ---------------------
      Host:            localhost / host.docker.internal
      Port:            ${MYSQL_PORT}
      Database:        ${MYSQL_DATABASE}
      User:            ${MYSQL_USER}
      Password:        ${MYSQL_PASSWORD}
      
      FILES INCLUDED:
      ---------------
      - keypool_logs_full_*.sql    (Complete database dump)
      - keypool_logs_schema.sql    (Structure only)
      - keypool_logs_data.sql      (Data only)
      - csv/logs_data.csv          (CSV export)
      
      RESTORE INSTRUCTIONS:
      ---------------------
      # Full restore:
      mysql -h localhost -P ${MYSQL_PORT} -u ${MYSQL_USER} -p${MYSQL_PASSWORD} ${MYSQL_DATABASE} < keypool_logs_full_*.sql
      
      # Or with Docker:
      docker exec -i keypool_mysql mysql -u ${MYSQL_USER} -p${MYSQL_PASSWORD} ${MYSQL_DATABASE} < keypool_logs_full_*.sql
      
      TABLE STATISTICS:
      -----------------
      $(docker exec keypool_mysql mysql -u ${MYSQL_USER} -p${MYSQL_PASSWORD} ${MYSQL_DATABASE} -e "
      SELECT 'logs_data' as Table_Name, COUNT(*) as Records FROM logs_data;
      " 2>/dev/null || echo "No statistics available")
      =========================================================
      EOF
    
    - cat artifacts/database/DB_INFO.txt
    - ls -lah artifacts/database/
    - echo 'Database exported successfully'
  
  artifacts:
    name: "database-export-$CI_COMMIT_SHORT_SHA-$CI_PIPELINE_ID"
    paths:
      - artifacts/database/
    expire_in: 90 days
    when: always
  
  when: manual
  allow_failure: true
  only:
    - main
    - develop
    - merge_requests

# Export Grafana dashboards and config separately
stop:export_grafana:
  stage: stop
  script:
    - echo 'Exporting Grafana configuration and dashboards...'
    - mkdir -p artifacts/grafana
    - mkdir -p artifacts/grafana/dashboards
    - mkdir -p artifacts/grafana/datasources
    - mkdir -p artifacts/grafana/screenshots
    
    # Check if Grafana is running
    - |
      if ! (sudo docker ps | grep -q grafana || docker ps | grep -q grafana); then
        echo " Grafana is not running. Attempting to export saved configurations only..."
      else
        echo "Grafana is running. Exporting live configuration..."
        
        # Export all dashboards
        echo 'Exporting dashboards via API...'
        curl -s -u ${GRAFANA_ADMIN_USER}:${GRAFANA_ADMIN_PASSWORD} \
          http://0.0.0.0:${GRAFANA_PORT}/api/search?type=dash-db \
          > artifacts/grafana/all_dashboards.json
        
        # Export specific dashboard
        curl -s -u ${GRAFANA_ADMIN_USER}:${GRAFANA_ADMIN_PASSWORD} \
          http://0.0.0.0:${GRAFANA_PORT}/api/dashboards/uid/keypool-logs-001 \
          > artifacts/grafana/dashboards/keypool-dashboard.json
        
        # Export datasources
        echo 'Exporting datasources...'
        curl -s -u ${GRAFANA_ADMIN_USER}:${GRAFANA_ADMIN_PASSWORD} \
          http://0.0.0.0:${GRAFANA_PORT}/api/datasources \
          > artifacts/grafana/datasources/all_datasources.json
        
        # Export alerts (if any)
        echo 'Exporting alerts...'
        curl -s -u ${GRAFANA_ADMIN_USER}:${GRAFANA_ADMIN_PASSWORD} \
          http://0.0.0.0:${GRAFANA_PORT}/api/alerts \
          > artifacts/grafana/alerts.json 2>/dev/null || echo "No alerts configured"
        
        # Export org preferences
        curl -s -u ${GRAFANA_ADMIN_USER}:${GRAFANA_ADMIN_PASSWORD} \
          http://0.0.0.0:${GRAFANA_PORT}/api/org/preferences \
          > artifacts/grafana/org_preferences.json
      fi
    
    # Copy static configuration files
    - echo 'Copying static configuration files...'
    - cp local/grafana/dashboards/keypool-logs-dashboard.json artifacts/grafana/dashboards/keypool-logs-dashboard-static.json 2>/dev/null || echo "No static dashboard"
    - cp local/grafana/config/datasources/mysql.yml artifacts/grafana/datasources/mysql-static.yml 2>/dev/null || echo "No static datasource"
    
    # Create Grafana info file
    - |
      cat > artifacts/grafana/GRAFANA_INFO.txt << EOF
      =========================================================
                    GRAFANA EXPORT INFO
      =========================================================
      Export Date:     $(date '+%Y-%m-%d %H:%M:%S %Z')
      Pipeline ID:     $CI_PIPELINE_ID
      Commit SHA:      $CI_COMMIT_SHORT_SHA
      Branch:          $CI_COMMIT_REF_NAME
      
      GRAFANA ACCESS:
      ---------------------
      URL:             http://0.0.0.0:${GRAFANA_PORT}
      Username:        ${GRAFANA_ADMIN_USER}
      Password:        ${GRAFANA_ADMIN_PASSWORD}
      
      MYSQL DATASOURCE:
      ---------------------
      Host:            host.docker.internal
      Port:            ${MYSQL_PORT}
      Database:        ${MYSQL_DATABASE}
      User:            ${MYSQL_USER}
      
      FILES EXPORTED:
      ---------------
      $(ls -la artifacts/grafana/ 2>/dev/null | tail -n +2 || echo "No files")
      
      IMPORT INSTRUCTIONS:
      ---------------------
      1. Start Grafana container
      2. Access Grafana at http://0.0.0.0:${GRAFANA_PORT}
      3. Login with credentials above
      4. Import dashboard from JSON file
      5. Configure MySQL datasource if needed
      
      =========================================================
      EOF
    
    - cat artifacts/grafana/GRAFANA_INFO.txt
    - echo 'Grafana configuration exported successfully'
  
  artifacts:
    name: "grafana-export-$CI_COMMIT_SHORT_SHA-$CI_PIPELINE_ID"
    paths:
      - artifacts/grafana/
    expire_in: 30 days
    when: always
  
  when: manual
  allow_failure: true
  only:
    - main
    - develop